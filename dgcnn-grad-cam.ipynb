{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-29T02:07:32.155826Z","iopub.execute_input":"2023-03-29T02:07:32.156681Z","iopub.status.idle":"2023-03-29T02:07:32.208446Z","shell.execute_reply.started":"2023-03-29T02:07:32.156639Z","shell.execute_reply":"2023-03-29T02:07:32.207480Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train3.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train_2_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/test_files.txt\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train4.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/train_files.txt\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train1.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train_3_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_test_0_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_test1.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_test0.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_test_1_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train_0_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train_4_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train_1_id2file.json\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train0.h5\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/shape_names.txt\n/kaggle/input/modelnet40-ply/modelnet40_ply_hdf5_2048/ply_data_train2.h5\n/kaggle/input/model-result/model.t7\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:32.211114Z","iopub.execute_input":"2023-03-29T02:07:32.212151Z","iopub.status.idle":"2023-03-29T02:07:33.325204Z","shell.execute_reply.started":"2023-03-29T02:07:32.212113Z","shell.execute_reply":"2023-03-29T02:07:33.323730Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Wed Mar 29 02:07:33 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install plyfile","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:33.330691Z","iopub.execute_input":"2023-03-29T02:07:33.331119Z","iopub.status.idle":"2023-03-29T02:07:46.222234Z","shell.execute_reply.started":"2023-03-29T02:07:33.331064Z","shell.execute_reply":"2023-03-29T02:07:46.221042Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting plyfile\n  Downloading plyfile-0.8.1-py3-none-any.whl (28 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from plyfile) (1.21.6)\nInstalling collected packages: plyfile\nSuccessfully installed plyfile-0.8.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import print_function\nimport os\nimport sys\nimport glob\nimport h5py\nimport numpy as np\nimport torch\nimport json\nimport cv2\nimport pickle\nfrom torch.utils.data import Dataset\nfrom plyfile import (PlyData, PlyElement, make2d, PlyParseError, PlyProperty)\nimport copy\nimport random\nfrom torch import nn\nfrom torch.nn.modules.conv import _ConvNd\nfrom torch.nn.modules.batchnorm import _BatchNorm\nimport torch.nn.init as initer\nimport torch.nn.functional as F\nimport argparse\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\nfrom torch.utils.data import DataLoader\nimport sklearn.metrics as metrics","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:46.226824Z","iopub.execute_input":"2023-03-29T02:07:46.227168Z","iopub.status.idle":"2023-03-29T02:07:49.426464Z","shell.execute_reply.started":"2023-03-29T02:07:46.227136Z","shell.execute_reply":"2023-03-29T02:07:49.425276Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **以下为data_prep_util.py**","metadata":{}},{"cell_type":"code","source":"\nBASE_DIR = os.path.dirname(os.path.abspath(os.getcwd()))\nsys.path.append(BASE_DIR)\nprint(BASE_DIR)\n\nSAMPLING_BIN = os.path.join(BASE_DIR, 'pcsample')\nprint(SAMPLING_BIN)\nSAMPLING_POINT_NUM = 2048\nSAMPLING_LEAF_SIZE = 0.005\n\nMODELNET40_PATH = '/kaggle/input/modelnet40-ply'\n\n\ndef export_ply(pc, filename):\n    vertex = np.zeros(pc.shape[0], dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])\n    for i in range(pc.shape[0]):\n        vertex[i] = (pc[i][0], pc[i][1], pc[i][2])\n    ply_out = PlyData([PlyElement.describe(vertex, 'vertex', comments=['vertices'])])\n    ply_out.write(filename)\n\n\n# Sample points on the obj shape\ndef get_sampling_command(obj_filename, ply_filename):\n    cmd = SAMPLING_BIN + ' ' + obj_filename\n    cmd += ' ' + ply_filename\n    cmd += ' -n_samples %d ' % SAMPLING_POINT_NUM\n    cmd += ' -leaf_size %f ' % SAMPLING_LEAF_SIZE\n    return cmd\n\n\n# --------------------------------------------------------------\n# Following are the helper functions to load MODELNET40 shapes\n# --------------------------------------------------------------\n\n# Read in the list of categories in MODELNET40\ndef get_category_names():\n    shape_names_file = os.path.join(MODELNET40_PATH, 'shape_names.txt')\n    shape_names = [line.rstrip() for line in open(shape_names_file)]\n    return shape_names\n\n\n# Return all the filepaths for the shapes in MODELNET40\ndef get_obj_filenames():\n    obj_filelist_file = os.path.join(MODELNET40_PATH, 'filelist.txt')\n    obj_filenames = [os.path.join(MODELNET40_PATH, line.rstrip()) for line in open(obj_filelist_file)]\n    print('Got %d obj files in modelnet40.' % len(obj_filenames))\n    return obj_filenames\n\n\n# Helper function to create the father folder and all subdir folders if not exist\ndef batch_mkdir(output_folder, subdir_list):\n    if not os.path.exists(output_folder):\n        os.mkdir(output_folder)\n    for subdir in subdir_list:\n        if not os.path.exists(os.path.join(output_folder, subdir)):\n            os.mkdir(os.path.join(output_folder, subdir))\n\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load HDF5 files\n# ----------------------------------------------------------------\n\n# Write numpy array data and label to h5_filename\ndef save_h5_data_label_normal(h5_filename, data, label, normal,\n                              data_dtype='float32', label_dtype='uint8', normal_dtype='float32'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n        'data', data=data,\n        compression='gzip', compression_opts=4,\n        dtype=data_dtype)\n    h5_fout.create_dataset(\n        'normal', data=normal,\n        compression='gzip', compression_opts=4,\n        dtype=normal_dtype)\n    h5_fout.create_dataset(\n        'label', data=label,\n        compression='gzip', compression_opts=1,\n        dtype=label_dtype)\n    h5_fout.close()\n\n\n# Write numpy array data and label to h5_filename\ndef save_h5(h5_filename, data, label, data_dtype='uint8', label_dtype='uint8'):\n    h5_fout = h5py.File(h5_filename, \"w\")\n    h5_fout.create_dataset(\n        'data', data=data,\n        compression='gzip', compression_opts=4,\n        dtype=data_dtype)\n    h5_fout.create_dataset(\n        'label', data=label,\n        compression='gzip', compression_opts=1,\n        dtype=label_dtype)\n    h5_fout.close()\n\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_normal(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    normal = f['normal'][:]\n    return (data, label, normal)\n\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    seg = f['pid'][:]\n    return (data, label, seg)\n\n\n# Read numpy array data and label from h5_filename\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    return (data, label)\n\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load PLY files\n# ----------------------------------------------------------------\n\n# Load PLY file\ndef load_ply_data(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata['vertex'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x, y, z in pc])\n    return pc_array\n\n\n# Load PLY file\ndef load_ply_normal(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata['normal'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x, y, z in pc])\n    return pc_array\n\n\n# Make up rows for Nxk array\n# Input Pad is 'edge' or 'constant'\ndef pad_arr_rows(arr, row, pad='edge'):\n    assert (len(arr.shape) == 2)\n    assert (arr.shape[0] <= row)\n    assert (pad == 'edge' or pad == 'constant')\n    if arr.shape[0] == row:\n        return arr\n    if pad == 'edge':\n        return np.lib.pad(arr, ((0, row - arr.shape[0]), (0, 0)), 'edge')\n    if pad == 'constant':\n        return np.lib.pad(arr, ((0, row - arr.shape[0]), (0, 0)), 'constant', (0, 0))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:49.428241Z","iopub.execute_input":"2023-03-29T02:07:49.429023Z","iopub.status.idle":"2023-03-29T02:07:49.457941Z","shell.execute_reply.started":"2023-03-29T02:07:49.428979Z","shell.execute_reply":"2023-03-29T02:07:49.457007Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle\n/kaggle/pcsample\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **以下为data.py**","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/input/modelnet40-ply && ls\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:49.459308Z","iopub.execute_input":"2023-03-29T02:07:49.459634Z","iopub.status.idle":"2023-03-29T02:07:50.414065Z","shell.execute_reply.started":"2023-03-29T02:07:49.459599Z","shell.execute_reply":"2023-03-29T02:07:50.412782Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"modelnet40_ply_hdf5_2048\n","output_type":"stream"}]},{"cell_type":"code","source":"def download_modelnet40():\n    BASE_DIR = os.path.dirname(os.path.abspath(os.getcwd()))\n    DATA_DIR = os.path.join(BASE_DIR, 'input/modelnet40-ply')\n    if not os.path.exists(DATA_DIR):\n        os.mkdir(DATA_DIR)\n    if not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n        zipfile = os.path.basename(www)\n        os.system('wget --no-check-certificate %s; unzip %s' % (www, zipfile))\n        os.system('mv %s %s' % ('modelnet40_ply_hdf5_2048', DATA_DIR))\n        os.system('rm %s' % (zipfile))\n\n\ndef load_data_cls(partition):\n    download_modelnet40()\n    BASE_DIR = os.path.dirname(os.path.abspath(os.getcwd()))\n    DATA_DIR = os.path.join(BASE_DIR, 'input/modelnet40-ply')\n    print(BASE_DIR,DATA_DIR)\n    all_data = []\n    all_label = []\n    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', '*%s*.h5'%partition)):\n        f = h5py.File(h5_name, 'r')\n        data = f['data'][:].astype('float32')\n        label = f['label'][:].astype('int64')\n        f.close()\n        all_data.append(data)\n        all_label.append(label)\n    all_data = np.concatenate(all_data, axis=0)\n    all_label = np.concatenate(all_label, axis=0)\n    return all_data, all_label\n\n    \n\ndef translate_pointcloud(pointcloud):\n    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])\n    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n       \n    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n    return translated_pointcloud\n\n\ndef jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):\n    N, C = pointcloud.shape\n    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)\n    return pointcloud\n\n\ndef rotate_pointcloud(pointcloud):\n    theta = np.pi*2 * np.random.uniform()\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n    pointcloud[:,[0,2]] = pointcloud[:,[0,2]].dot(rotation_matrix) # random rotation (x,z)\n    return pointcloud\n\n\nclass ModelNet40(Dataset):\n    def __init__(self, num_points, partition='train'):\n        self.data, self.label = load_data_cls(partition)\n        self.num_points = num_points\n        self.partition = partition        \n\n    def __getitem__(self, item):\n        pointcloud = self.data[item][:self.num_points]\n        label = self.label[item]\n        if self.partition == 'train':\n            pointcloud = translate_pointcloud(pointcloud)\n            np.random.shuffle(pointcloud)\n        return pointcloud, label\n\n    def __len__(self):\n        return self.data.shape[0]\n\n\nif __name__ == '__main__':\n    train = ModelNet40(1024)\n    test = ModelNet40(1024, 'test')\n    data, label = train[0]\n    print(data.shape)\n    print(label.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:50.416522Z","iopub.execute_input":"2023-03-29T02:07:50.416949Z","iopub.status.idle":"2023-03-29T02:07:56.405842Z","shell.execute_reply.started":"2023-03-29T02:07:50.416906Z","shell.execute_reply":"2023-03-29T02:07:56.404665Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle /kaggle/input/modelnet40-ply\n/kaggle /kaggle/input/modelnet40-ply\n(1024, 3)\n(1,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **以下为util.py**","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef set_seed(seed=1):\n    print('Using random seed', seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n\ndef str2bool(v):\n    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n\n\ndef get_lr(optimizer):\n    return optimizer.param_groups[0]['lr']\n\n\ndef adjust_lr(optimizer, new_lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = new_lr\n\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv2d') != -1:\n        nn.init.xavier_normal_(m.weight.data)\n        try:\n            nn.init.constant_(m.bias.data, 0.0)\n        except AttributeError:\n            pass\n    elif classname.find('Linear') != -1:\n        nn.init.xavier_normal_(m.weight.data)\n        try:\n            nn.init.constant_(m.bias.data, 0.0)\n        except AttributeError:\n            pass\n\n\ndef bn_momentum_adjust(m, momentum):\n    if isinstance(m, nn.BatchNorm2d) or \\\n            isinstance(m, nn.BatchNorm1d):\n        m.momentum = momentum\n\n\ndef intersectionAndUnion(output, target, K, ignore_index=255):\n    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n    assert (output.ndim in [1, 2, 3])\n    assert output.shape == target.shape\n    output = output.reshape(output.size).copy()\n    target = target.reshape(target.size)\n    output[np.where(target == ignore_index)[0]] = 255\n    target[np.where(target == ignore_index)[0]] = 255\n    intersection = output[np.where(output == target)[0]]\n    area_intersection, _ = np.histogram(intersection, bins=np.arange(K+1))\n    area_output, _ = np.histogram(output, bins=np.arange(K+1))\n    area_target, _ = np.histogram(target, bins=np.arange(K+1))\n    area_union = area_output + area_target - area_intersection\n    return area_intersection, area_union, area_target\n\n\ndef calc_victim_value(class_value, label, victim_class):\n    values = []\n    for lbl in victim_class:\n        if label is None or (label == lbl).any():\n            values.append(class_value[lbl])\n    return np.mean(values)\n\n\ndef check_makedirs(dir_name):\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef init_weights(model, conv='kaiming', batchnorm='normal', linear='kaiming', lstm='kaiming'):\n    \"\"\"\n    :param model: Pytorch Model which is nn.Module\n    :param conv:  'kaiming' or 'xavier'\n    :param batchnorm: 'normal' or 'constant'\n    :param linear: 'kaiming' or 'xavier'\n    :param lstm: 'kaiming' or 'xavier'\n    \"\"\"\n    for m in model.modules():\n        if isinstance(m, (_ConvNd)):\n            if conv == 'kaiming':\n                initer.kaiming_normal_(m.weight)\n            elif conv == 'xavier':\n                initer.xavier_normal_(m.weight)\n            else:\n                raise ValueError(\"init type of conv error.\\n\")\n            if m.bias is not None:\n                initer.constant_(m.bias, 0)\n\n        elif isinstance(m, _BatchNorm):\n            if batchnorm == 'normal':\n                initer.normal_(m.weight, 1.0, 0.02)\n            elif batchnorm == 'constant':\n                initer.constant_(m.weight, 1.0)\n            else:\n                raise ValueError(\"init type of batchnorm error.\\n\")\n            initer.constant_(m.bias, 0.0)\n\n        elif isinstance(m, nn.Linear):\n            if linear == 'kaiming':\n                initer.kaiming_normal_(m.weight)\n            elif linear == 'xavier':\n                initer.xavier_normal_(m.weight)\n            else:\n                raise ValueError(\"init type of linear error.\\n\")\n            if m.bias is not None:\n                initer.constant_(m.bias, 0)\n\n        elif isinstance(m, nn.LSTM):\n            for name, param in m.named_parameters():\n                if 'weight' in name:\n                    if lstm == 'kaiming':\n                        initer.kaiming_normal_(param)\n                    elif lstm == 'xavier':\n                        initer.xavier_normal_(param)\n                    else:\n                        raise ValueError(\"init type of lstm error.\\n\")\n                elif 'bias' in name:\n                    initer.constant_(param, 0)\n\n\ndef convert_to_syncbn(model):\n    def recursive_set(cur_module, name, module):\n        if len(name.split('.')) > 1:\n            recursive_set(\n                getattr(cur_module, name[:name.find('.')]), name[name.find('.')+1:], module)\n        else:\n            setattr(cur_module, name, module)\n    from sync_bn import SynchronizedBatchNorm1d, SynchronizedBatchNorm2d, \\\n        SynchronizedBatchNorm3d\n    for name, m in model.named_modules():\n        if isinstance(m, nn.BatchNorm1d):\n            recursive_set(model, name, SynchronizedBatchNorm1d(\n                m.num_features, m.eps, m.momentum, m.affine))\n        elif isinstance(m, nn.BatchNorm2d):\n            recursive_set(model, name, SynchronizedBatchNorm2d(\n                m.num_features, m.eps, m.momentum, m.affine))\n        elif isinstance(m, nn.BatchNorm3d):\n            recursive_set(model, name, SynchronizedBatchNorm3d(\n                m.num_features, m.eps, m.momentum, m.affine))\n\n\ndef lbl2rgb(label, names):\n    \"\"\"Convert label to rgb colors.\n    label: [N]\n    \"\"\"\n    from config import NAME2COLOR\n    if len(names) == 13:\n        colors = NAME2COLOR['S3DIS']\n    else:\n        colors = NAME2COLOR['ScanNet']\n    rgb = np.zeros((label.shape[0], 3))\n    uni_lbl = np.unique(label).astype(np.uint8)\n    for lbl in uni_lbl:\n        mask = (label == lbl)\n        rgb[mask] = np.tile(np.array(\n            colors[names[lbl]])[None, :], (mask.sum(), 1))\n    return rgb\n\n\ndef convert2vis(xyz, label, names):\n    \"\"\"Assign color to each point according to label.\"\"\"\n    rgb = lbl2rgb(label, names) * 255.\n    data = np.concatenate([xyz, rgb], axis=1)\n    return data\n\n\ndef proc_pert(points, gt, pred, folder,\n              names, part=False, ignore_label=255):\n    \"\"\"Process and save files for visulization in perturbation attack.\"\"\"\n    check_makedirs(folder)\n    lbl2cls = {i: names[i] for i in range(len(names))}\n\n    np.savetxt(os.path.join(folder, 'all_points.txt'), points, delimiter=';')\n    gt_seg = convert2vis(points[gt != ignore_label, :3],\n                         gt[gt != ignore_label], names)\n    pred_seg = convert2vis(points[gt != ignore_label, :3],\n                           pred[gt != ignore_label], names)\n    np.savetxt(os.path.join(folder, 'gt.txt'),\n               gt_seg, delimiter=';')\n    np.savetxt(os.path.join(folder, 'pred.txt'),\n               pred_seg, delimiter=';')\n    if part:\n        uni_lbl = np.unique(gt[gt != ignore_label]).astype(np.uint8)\n        for lbl in uni_lbl:\n            lbl = int(lbl)\n            mask = (gt == lbl)\n            sel_points = points[mask]\n            mask = (gt[gt != ignore_label] == lbl)\n            sel_seg = pred_seg[mask]\n            np.savetxt(\n                os.path.join(folder, '{}_{}_points.txt'.format(\n                    lbl, lbl2cls[lbl])),\n                sel_points, delimiter=';')\n            np.savetxt(\n                os.path.join(folder, '{}_{}_pred.txt'.format(\n                    lbl, lbl2cls[lbl])),\n                sel_seg, delimiter=';')\n\n\ndef proc_add(points, noise, gt, pred, noise_pred, folder,\n             names, part=False, ignore_label=255):\n    \"\"\"Process and save files for visulization in adding attack.\"\"\"\n    check_makedirs(folder)\n    lbl2cls = {i: names[i] for i in range(len(names))}\n\n    np.savetxt(os.path.join(folder, 'all_points.txt'), points, delimiter=';')\n    np.savetxt(os.path.join(folder, 'noise_points.txt'), noise, delimiter=';')\n    gt_seg = convert2vis(points[gt != ignore_label, :3],\n                         gt[gt != ignore_label], names)\n    pred_seg = convert2vis(points[gt != ignore_label, :3],\n                           pred[gt != ignore_label], names)\n    noise_seg = convert2vis(noise[:, :3], noise_pred, names)\n    np.savetxt(os.path.join(folder, 'gt.txt'),\n               gt_seg, delimiter=';')\n    np.savetxt(os.path.join(folder, 'pred.txt'),\n               pred_seg, delimiter=';')\n    np.savetxt(os.path.join(folder, 'noise_pred.txt'),\n               noise_seg, delimiter=';')\n    if part:\n        uni_lbl = np.unique(gt[gt != ignore_label]).astype(np.uint8)\n        for lbl in uni_lbl:\n            lbl = int(lbl)\n            mask = (gt == lbl)\n            sel_points = points[mask]\n            mask = (gt[gt != ignore_label] == lbl)\n            sel_seg = pred_seg[mask]\n            np.savetxt(\n                os.path.join(folder, '{}_{}_points.txt'.format(\n                    lbl, lbl2cls[lbl])),\n                sel_points, delimiter=';')\n            np.savetxt(\n                os.path.join(folder, '{}_{}_pred.txt'.format(\n                    lbl, lbl2cls[lbl])),\n                sel_seg, delimiter=';')\n\n\ndef save_vis(pred_root, save_root, data_root):\n    from config import CLASS_NAMES\n    if 'S3DIS' in data_root:  # save Area5 data\n        names = CLASS_NAMES['S3DIS']['other']\n        gt_save = load_pickle(\n            os.path.join(pred_root, 'gt_5.pickle'))['gt']\n        pred_save = load_pickle(\n            os.path.join(pred_root, 'pred_5.pickle'))['pred']\n        assert len(gt_save) == len(pred_save)\n        all_rooms = sorted(os.listdir(data_root))\n        all_rooms = [\n            room for room in all_rooms if 'Area_5' in room\n        ]\n        assert len(gt_save) == len(all_rooms)\n        check_makedirs(save_root)\n        for i, room in enumerate(all_rooms):\n            points = np.load(os.path.join(data_root, room))[:, :6]\n            folder = os.path.join(save_root, room[:-4])\n            check_makedirs(folder)\n            proc_pert(points, gt_save[i], pred_save[i],\n                      folder, names, part=True)\n    elif 'ScanNet' in data_root:  # save val set data\n        names = CLASS_NAMES['ScanNet']['other']\n        gt_save = load_pickle(\n            os.path.join(pred_root, 'gt_val.pickle'))['gt']\n        pred_save = load_pickle(\n            os.path.join(pred_root, 'pred_val.pickle'))['pred']\n        assert len(gt_save) == len(pred_save)\n        data_file = os.path.join(\n            data_root, 'scannet_val_rgb21c_pointid.pickle')\n        file_pickle = open(data_file, 'rb')\n        xyz_all = pickle.load(file_pickle)\n        file_pickle.close()\n        assert len(xyz_all) == len(gt_save)\n        with open(os.path.join(\n                data_root, 'meta_data/scannetv2_val.txt')) as fl:\n            scene_id = fl.read().splitlines()\n        assert len(scene_id) == len(gt_save)\n        check_makedirs(save_root)\n        for i in range(len(gt_save)):\n            points = xyz_all[i][:, :6]\n            folder = os.path.join(save_root, scene_id[i])\n            check_makedirs(folder)\n            proc_pert(points, gt_save[i], pred_save[i],\n                      folder, names, part=True)\n\n\ndef save_vis_mink(pred_root, save_root, data_root):\n    from config import CLASS_NAMES\n\n    def load_data(file_name):\n        plydata = PlyData.read(file_name)\n        data = plydata.elements[0].data\n        coords = np.array([data['x'], data['y'], data['z']],\n                          dtype=np.float32).T\n        colors = np.array([data['red'], data['green'],\n                           data['blue']], dtype=np.float32).T\n        return np.concatenate([coords, colors], axis=1)\n\n    if 'S3DIS' in data_root:  # save Area5 data\n        names = CLASS_NAMES['S3DIS']['mink']\n        gt_save = load_pickle(\n            os.path.join(pred_root, 'gt_5.pickle'))['gt']\n        pred_save = load_pickle(\n            os.path.join(pred_root, 'pred_5.pickle'))['pred']\n        assert len(gt_save) == len(pred_save)\n        data_root = os.path.join(data_root, 'Area_5')\n        all_rooms = sorted(os.listdir(data_root))\n        assert len(all_rooms) == len(gt_save)\n        check_makedirs(save_root)\n\n        for i, room in enumerate(all_rooms):\n            data = os.path.join(data_root, room)\n            points = load_data(data)\n            folder = os.path.join(\n                save_root, 'Area_5_{}'.format(room[:-4]))\n            check_makedirs(folder)\n            proc_pert(points, gt_save[i], pred_save[i],\n                      folder, names, part=True)\n    elif 'ScanNet' in data_root:  # save val set\n        names = CLASS_NAMES['ScanNet']['mink']\n        gt_save = load_pickle(\n            os.path.join(pred_root, 'gt_val.pickle'))['gt']\n        pred_save = load_pickle(\n            os.path.join(pred_root, 'pred_val.pickle'))['pred']\n        assert len(gt_save) == len(pred_save)\n        data_root = os.path.join(data_root, 'train')\n        with open(os.path.join(\n                data_root, 'scannetv2_val.txt'), 'r') as f:\n            all_rooms = f.readlines()\n        all_rooms = [room[:-1] for room in all_rooms]\n        assert len(all_rooms) == len(gt_save)\n        check_makedirs(save_root)\n\n        for i, room in enumerate(all_rooms):\n            data = os.path.join(data_root, room)\n            points = load_data(data)\n            folder = os.path.join(save_root, room[:-4])\n            check_makedirs(folder)\n            proc_pert(points, gt_save[i], pred_save[i],\n                      folder, names, part=True)\n\n\ndef save_vis_from_pickle(pkl_root, save_root=None, room_idx=52,\n                         room_name='scene0354_00'):\n    names = [\n        'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table',\n        'door', 'window', 'bookshelf', 'picture', 'counter', 'desk',\n        'curtain', 'refrigerator', 'showercurtain', 'toilet', 'sink',\n        'bathtub', 'otherfurniture'\n    ]\n    data = load_pickle(pkl_root)\n    points = data['data'][room_idx]\n    pred = data['pred'][room_idx]\n    gt = data['gt'][room_idx]\n    if save_root is None:\n        save_root = os.path.dirname(pkl_root)\n    save_folder = os.path.join(save_root, room_name)\n    proc_pert(points, gt, pred, save_folder, names, part=True)\n\n\ndef save_pickle(filename, dict_data):\n    with open(filename, 'wb') as handle:\n        pickle.dump(dict_data, handle,\n                    protocol=pickle.HIGHEST_PROTOCOL)\n\n\ndef load_pickle(filename):\n    with open(filename, 'rb') as f:\n        data = pickle.load(f)\n    return data\n\n\ndef load_s3dis_instance(folder, name2cls, load_name=['chair']):\n    \"\"\"Load S3DIS room in a Inst Seg format.\n    Get each instance separately.\n\n    If load_name is None or [], return all instances.\n    Returns a list of [np.array of [N, 6], label]\n    \"\"\"\n    cls2name = {name2cls[name]: name for name in name2cls.keys()}\n    anno_path = os.path.join(folder, 'Annotations')\n    points_list = []\n    labels_list = []\n    idx = 0\n    files = glob.glob(os.path.join(anno_path, '*.txt'))\n    files.sort()\n\n    for f in files:\n        cls = os.path.basename(f).split('_')[0]\n        if cls not in name2cls.keys():\n            cls = 'clutter'\n        points = np.loadtxt(f)  # [N, 6]\n        num = points.shape[0]\n        points_list.append(points)\n        labels_list.append((idx, idx + num, name2cls[cls]))\n        idx += num\n\n    # normalize points coords by minus min\n    data = np.concatenate(points_list, 0)\n    xyz_min = np.amin(data, axis=0)[0:3]\n    data[:, 0:3] -= xyz_min\n\n    # rearrange to separate instances\n    if load_name is None or not load_name:\n        load_name = list(name2cls.keys())\n    instances = [\n        [data[pair[0]:pair[1]], pair[2]] for pair in labels_list if\n        cls2name[pair[2]] in load_name\n    ]\n    return instances\n\n\ndef cal_loss(pred, gold, smoothing=False, ignore_index=255):\n    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n\n    gold = gold.contiguous().view(-1)\n\n    if smoothing:\n        eps = 0.2\n        n_class = pred.size(1)\n\n        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n        log_prb = F.log_softmax(pred, dim=1)\n\n        loss = -(one_hot * log_prb).sum(dim=1).mean()\n    else:\n        loss = F.cross_entropy(\n            pred, gold, reduction='mean',\n            ignore_index=ignore_index)\n\n    return loss\n\n\nclass IOStream():\n    def __init__(self, path):\n        self.f = open(path, 'a')\n\n    def cprint(self, text):\n        print(text)\n        self.f.write(text+'\\n')\n        self.f.flush()\n\n    def close(self):\n        self.f.close()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-03-29T02:07:56.407792Z","iopub.execute_input":"2023-03-29T02:07:56.408185Z","iopub.status.idle":"2023-03-29T02:07:56.479981Z","shell.execute_reply.started":"2023-03-29T02:07:56.408146Z","shell.execute_reply":"2023-03-29T02:07:56.478662Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **以下为model.py**","metadata":{}},{"cell_type":"code","source":"def knn(x, k):\n    inner = -2*torch.matmul(x.transpose(2, 1), x)\n    xx = torch.sum(x**2, dim=1, keepdim=True)\n    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n \n    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n    return idx\n\n\ndef get_graph_feature(x, k=20, idx=None, dim9=False):\n    batch_size = x.size(0)\n    num_points = x.size(2)\n    x = x.view(batch_size, -1, num_points)\n    if idx is None:\n        if dim9 == False:\n            idx = knn(x, k=k)   # (batch_size, num_points, k)\n        else:\n            idx = knn(x[:, 6:], k=k)\n    device = torch.device('cuda')\n\n    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n\n    idx = idx + idx_base\n\n    idx = idx.view(-1)\n \n    _, num_dims, _ = x.size()\n\n    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n    feature = x.view(batch_size*num_points, -1)[idx, :]\n    feature = feature.view(batch_size, num_points, k, num_dims) \n    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n    \n    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n  \n    return feature      # (batch_size, 2*num_dims, num_points, k)\n\n\nclass PointNet(nn.Module):\n    def __init__(self, args, output_channels=40):\n        super(PointNet, self).__init__()\n        self.args = args\n        self.conv1 = nn.Conv1d(3, 64, kernel_size=1, bias=False)\n        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n        self.conv3 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=1, bias=False)\n        self.conv5 = nn.Conv1d(128, args.emb_dims, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n        self.linear1 = nn.Linear(args.emb_dims, 512, bias=False)\n        self.bn6 = nn.BatchNorm1d(512)\n        self.dp1 = nn.Dropout()\n        self.linear2 = nn.Linear(512, output_channels)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = F.relu(self.bn5(self.conv5(x)))\n        x = F.adaptive_max_pool1d(x, 1).squeeze()\n        x = F.relu(self.bn6(self.linear1(x)))\n        x = self.dp1(x)\n        x = self.linear2(x)\n        return x\n\n\nclass DGCNN_cls(nn.Module):\n    def __init__(self, args, output_channels=40):\n        super(DGCNN_cls, self).__init__()\n        self.args = args\n        self.k = args.k\n        \n        self.gradient = None\n        self.activations = None\n\n        def forward_hook(module, input, output):\n            self.activations = output\n\n        def backward_hook(module, grad_input, grad_output):\n            self.gradient = grad_output[0]\n    \n        self.bn1 = nn.BatchNorm2d(64)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n\n        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n                                   self.bn1,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n                                   self.bn2,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n                                   self.bn3,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n                                   self.bn4,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n                                   self.bn5,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)\n        self.bn6 = nn.BatchNorm1d(512)\n        self.dp1 = nn.Dropout(p=args.dropout)\n        self.linear2 = nn.Linear(512, 256)\n        self.bn7 = nn.BatchNorm1d(256)\n        self.dp2 = nn.Dropout(p=args.dropout)\n        self.linear3 = nn.Linear(256, output_channels)\n        \n        self.conv4.register_forward_hook(forward_hook)\n        self.conv4.register_full_backward_hook(backward_hook)\n        self.conv5.register_forward_hook(forward_hook)\n        self.conv5.register_full_backward_hook(backward_hook)\n        \n#     def compute_grad_cam(self):\n#         print(\"Gradient shape:\", self.gradient.shape)\n#         print(\"Activations shape:\", self.activations.shape)\n\n#         channel_weights = torch.mean(self.gradient, dim=2)  # Global average pooling\n#         grad_cam = torch.matmul(channel_weights, self.activations[0]).squeeze()\n\n#         grad_cam = torch.relu(grad_cam)\n#         return grad_cam\n\n    def compute_grad_cam(self):\n        batch_size, num_filters, num_points, num_classes = self.gradient.size()\n        channel_weights = torch.mean(self.gradient, dim=(2, 3))  # Global average pooling\n        grad_cam = torch.zeros((batch_size, num_points)).cuda()\n\n        for i, w in enumerate(channel_weights[0]):\n            grad_cam += w * self.activations[0, :, i]\n\n        grad_cam = torch.relu(grad_cam)\n        return grad_cam\n\n\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        x = get_graph_feature(x, k=self.k)      # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n        x1 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n\n        x = get_graph_feature(x1, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n        x = self.conv2(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n        x2 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n\n        x = get_graph_feature(x2, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n        x = self.conv3(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 128, num_points, k)\n        x3 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)\n\n        x = get_graph_feature(x3, k=self.k)     # (batch_size, 128, num_points) -> (batch_size, 128*2, num_points, k)\n        x = self.conv4(x)                       # (batch_size, 128*2, num_points, k) -> (batch_size, 256, num_points, k)\n        x4 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 256, num_points, k) -> (batch_size, 256, num_points)\n\n        x = torch.cat((x1, x2, x3, x4), dim=1)  # (batch_size, 64+64+128+256, num_points)\n\n        x = self.conv5(x)                       # (batch_size, 64+64+128+256, num_points) -> (batch_size, emb_dims, num_points)\n        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n        x = torch.cat((x1, x2), 1)              # (batch_size, emb_dims*2)\n\n        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2) # (batch_size, emb_dims*2) -> (batch_size, 512)\n        x = self.dp1(x)\n        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2) # (batch_size, 512) -> (batch_size, 256)\n        x = self.dp2(x)\n        x = self.linear3(x)                                             # (batch_size, 256) -> (batch_size, output_channels)\n        \n        return x\n\n\nclass Transform_Net(nn.Module):\n    def __init__(self, args):\n        super(Transform_Net, self).__init__()\n        self.args = args\n        self.k = 3\n\n        self.bn1 = nn.BatchNorm2d(64)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n\n        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n                                   self.bn1,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, bias=False),\n                                   self.bn2,\n                                   nn.LeakyReLU(negative_slope=0.2))\n        self.conv3 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1, bias=False),\n                                   self.bn3,\n                                   nn.LeakyReLU(negative_slope=0.2))\n\n        self.linear1 = nn.Linear(1024, 512, bias=False)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.linear2 = nn.Linear(512, 256, bias=False)\n        self.bn4 = nn.BatchNorm1d(256)\n\n        self.transform = nn.Linear(256, 3*3)\n        initer.constant_(self.transform.weight, 0)\n        initer.eye_(self.transform.bias.view(3, 3))\n\n    def forward(self, x):\n        batch_size = x.size(0)\n\n        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n        x = self.conv2(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 128, num_points, k)\n        x = x.max(dim=-1, keepdim=False)[0]     # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)\n\n        x = self.conv3(x)                       # (batch_size, 128, num_points) -> (batch_size, 1024, num_points)\n        x = x.max(dim=-1, keepdim=False)[0]     # (batch_size, 1024, num_points) -> (batch_size, 1024)\n\n        x = F.leaky_relu(self.bn3(self.linear1(x)), negative_slope=0.2)     # (batch_size, 1024) -> (batch_size, 512)\n        x = F.leaky_relu(self.bn4(self.linear2(x)), negative_slope=0.2)     # (batch_size, 512) -> (batch_size, 256)\n\n        x = self.transform(x)                   # (batch_size, 256) -> (batch_size, 3*3)\n        x = x.view(batch_size, 3, 3)            # (batch_size, 3*3) -> (batch_size, 3, 3)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:35:32.326500Z","iopub.execute_input":"2023-03-29T02:35:32.326960Z","iopub.status.idle":"2023-03-29T02:35:32.371734Z","shell.execute_reply.started":"2023-03-29T02:35:32.326923Z","shell.execute_reply":"2023-03-29T02:35:32.370709Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# **Grad-Cam可视化**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef visualize_grad_cam(grad_cam, point_cloud, point_size=5):\n    grad_cam = grad_cam.detach().cpu().numpy()\n    grad_cam = (grad_cam - np.min(grad_cam)) / (np.max(grad_cam) - np.min(grad_cam))  # Normalize Grad-CAM\n    point_cloud = point_cloud.detach().cpu().numpy()\n\n    colormap = plt.get_cmap(\"viridis\")  # Choose a colormap\n    colors = colormap(grad_cam)\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Display the point cloud colored by the Grad-CAM heatmap\n    ax.scatter(point_cloud[0], point_cloud[1], point_cloud[2], c=colors[0], s=point_size)  # Use the first row of colors\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:07:56.528738Z","iopub.execute_input":"2023-03-29T02:07:56.529100Z","iopub.status.idle":"2023-03-29T02:07:56.538386Z","shell.execute_reply.started":"2023-03-29T02:07:56.529050Z","shell.execute_reply":"2023-03-29T02:07:56.537133Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **以下为main_cls.py**","metadata":{}},{"cell_type":"code","source":"def _init_():\n    if not os.path.exists('outputs'):\n        os.makedirs('outputs')\n    if not os.path.exists('outputs/'+args.exp_name):\n        os.makedirs('outputs/'+args.exp_name)\n    if not os.path.exists('outputs/'+args.exp_name+'/'+'models'):\n        os.makedirs('outputs/'+args.exp_name+'/'+'models')\n\ndef train(args, io):\n    train_loader = DataLoader(ModelNet40(partition='train', num_points=args.num_points), num_workers=2,\n                              batch_size=args.batch_size, shuffle=True, drop_last=True)\n    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2,\n                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n\n    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n\n    #Try to load models\n    if args.model == 'pointnet':\n        model = PointNet(args).to(device)\n    elif args.model == 'dgcnn':\n        model = DGCNN_cls(args).to(device)\n    else:\n        raise Exception(\"Not implemented\")\n\n    print(str(model))\n\n    model = nn.DataParallel(model)\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n\n    if args.use_sgd:\n        print(\"Use SGD\")\n        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n    else:\n        print(\"Use Adam\")\n        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n\n    if args.scheduler == 'cos':\n        scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=1e-3)\n    elif args.scheduler == 'step':\n        scheduler = StepLR(opt, step_size=20, gamma=0.7)\n    \n    criterion = cal_loss\n\n    best_test_acc = 0\n    for epoch in range(args.epochs):\n        ####################\n        # Train\n        ####################\n        train_loss = 0.0\n        count = 0.0\n        model.train()\n        train_pred = []\n        train_true = []\n        for data, label in train_loader:\n            data, label = data.to(device), label.to(device).squeeze()\n            data = data.permute(0, 2, 1)\n            batch_size = data.size()[0]\n            opt.zero_grad()\n            logits = model(data)\n            loss = criterion(logits, label)\n            loss.backward()\n            opt.step()\n            preds = logits.max(dim=1)[1]\n            count += batch_size\n            train_loss += loss.item() * batch_size\n            train_true.append(label.cpu().numpy())\n            train_pred.append(preds.detach().cpu().numpy())\n        if args.scheduler == 'cos':\n            scheduler.step()\n        elif args.scheduler == 'step':\n            if opt.param_groups[0]['lr'] > 1e-5:\n                scheduler.step()\n            if opt.param_groups[0]['lr'] < 1e-5:\n                for param_group in opt.param_groups:\n                    param_group['lr'] = 1e-5\n\n        train_true = np.concatenate(train_true)\n        train_pred = np.concatenate(train_pred)\n        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,\n                                                                                 train_loss*1.0/count,\n                                                                                 metrics.accuracy_score(\n                                                                                     train_true, train_pred),\n                                                                                 metrics.balanced_accuracy_score(\n                                                                                     train_true, train_pred))\n        io.cprint(outstr)\n\n        ####################\n        # Test\n        ####################\n        test_loss = 0.0\n        count = 0.0\n        model.eval()\n        test_pred = []\n        test_true = []\n        for data, label in test_loader:\n            data, label = data.to(device), label.to(device).squeeze()\n            data = data.permute(0, 2, 1)\n            batch_size = data.size()[0]\n            logits = model(data)\n            loss = criterion(logits, label)\n            preds = logits.max(dim=1)[1]\n            count += batch_size\n            test_loss += loss.item() * batch_size\n            test_true.append(label.cpu().numpy())\n            test_pred.append(preds.detach().cpu().numpy())\n        test_true = np.concatenate(test_true)\n        test_pred = np.concatenate(test_pred)\n        test_acc = metrics.accuracy_score(test_true, test_pred)\n        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,\n                                                                              test_loss*1.0/count,\n                                                                              test_acc,\n                                                                              avg_per_class_acc)\n        io.cprint(outstr)\n        if test_acc >= best_test_acc:\n            best_test_acc = test_acc\n            torch.save(model.state_dict(), 'outputs/%s/models/model.t7' % args.exp_name)\n\n\ndef test(args, io):\n    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points),\n                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n\n    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n\n    #Try to load models\n    if args.model == 'pointnet':\n        model = PointNet(args).to(device)\n    elif args.model == 'dgcnn':\n        model = DGCNN_cls(args).to(device)\n    else:\n        raise Exception(\"Not implemented\")\n\n    model = nn.DataParallel(model)\n    model.load_state_dict(torch.load(args.model_path))\n    model = model.eval()\n    test_acc = 0.0\n    count = 0.0\n    test_true = []\n    test_pred = []\n    \n#     for data, label in test_loader:\n\n#         data, label = data.to(device), label.to(device).squeeze()\n#         data = data.permute(0, 2, 1)\n#         batch_size = data.size()[0]\n#         logits = model(data)\n#         preds = logits.max(dim=1)[1]\n#         test_true.append(label.cpu().numpy())\n#         test_pred.append(preds.detach().cpu().numpy())\n\n\n    for i, (data, label) in enumerate(test_loader):\n        data, label = data.to(device), label.to(device).squeeze()\n        data = data.permute(0, 2, 1)\n        batch_size = data.size()[0]\n\n        logits = model(data)\n        preds = logits.max(dim=1)[1]\n\n        with torch.no_grad():  # Disable gradient computation for storing predictions\n            test_true.append(label.cpu().numpy())\n            test_pred.append(preds.detach().cpu().numpy())\n\n    # Calculate Grad-CAM for a specific batch index\n    batch_index = 0\n    data, label = test_loader.dataset[batch_index]\n    data = torch.from_numpy(data).unsqueeze(0).to(device)  # Convert to tensor, add batch dimension, and move to device\n    label = torch.tensor(label).unsqueeze(0).to(device).squeeze()  # Convert to tensor, add batch dimension, and move to device\n\n\n    logits = model(data)\n    preds = logits.max(dim=1)[1]\n\n    target_class = torch.argmax(logits, dim=1)[0]  # Choose the class with the highest logit\n    one_hot = torch.zeros_like(logits)\n    one_hot[0, target_class] = 1\n\n    # Backward pass for the target class\n    model.zero_grad()\n    logits.backward(gradient=one_hot, retain_graph=True)\n\n    # Compute Grad-CAM\n    grad_cam = model.module.compute_grad_cam()  # Note the addition of .module when using DataParallel\n    point_cloud = data[0, :3, :]  # Assuming input_data is the input point cloud tensor with shape (batch_size, num_dims, num_points)\n    visualize_grad_cam(grad_cam.view(-1), point_cloud.T)\n\n                \n    test_true = np.concatenate(test_true)\n    test_pred = np.concatenate(test_pred)\n    test_acc = metrics.accuracy_score(test_true, test_pred)\n    avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n    outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)\n    io.cprint(outstr)\n\n\nif __name__ == \"__main__\":\n    # Training settings\n    parser = argparse.ArgumentParser(description='Point Cloud Recognition')\n    parser.add_argument('--exp_name', type=str, default='DGCNN_GC', metavar='N',\n                        help='Name of the experiment')\n    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',\n                        choices=['pointnet', 'dgcnn'],\n                        help='Model to use, [pointnet, dgcnn]')\n    parser.add_argument('--dataset', type=str, default='modelnet40', metavar='N',\n                        choices=['modelnet40'])\n    parser.add_argument('--batch_size', type=int, default=32, metavar='batch_size',\n                        help='Size of batch)')\n    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',\n                        help='Size of batch)')\n    parser.add_argument('--epochs', type=int, default=250, metavar='N',\n                        help='number of episode to train ')\n    parser.add_argument('--use_sgd', type=bool, default=True,\n                        help='Use SGD')\n    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n                        help='learning rate (default: 0.001, 0.1 if using sgd)')\n    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n                        help='SGD momentum (default: 0.9)')\n    parser.add_argument('--scheduler', type=str, default='cos', metavar='N',\n                        choices=['cos', 'step'],\n                        help='Scheduler to use, [cos, step]')\n    parser.add_argument('--no_cuda', type=bool, default=False,\n                        help='enables CUDA training')\n    parser.add_argument('--seed', type=int, default=1, metavar='S',\n                        help='random seed (default: 1)')\n    parser.add_argument('--eval', type=bool,  default=False,\n                        help='evaluate the model')\n    parser.add_argument('--num_points', type=int, default=1024,\n                        help='num of points to use')\n    parser.add_argument('--dropout', type=float, default=0.5,\n                        help='initial dropout rate')\n    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',\n                        help='Dimension of embeddings')\n    parser.add_argument('--k', type=int, default=20, metavar='N',\n                        help='Num of nearest neighbors to use')\n    parser.add_argument('--model_path', type=str, default='/kaggle/input/model-result/model.t7', metavar='N',\n                        help='Pretrained model path')\n    args = parser.parse_args(['--eval','True'])\n\n    _init_()\n\n    io = IOStream('outputs/' + args.exp_name + '/run.log')\n    io.cprint(str(args))\n\n    args.cuda = not args.no_cuda and torch.cuda.is_available()\n    torch.manual_seed(args.seed)\n    if args.cuda:\n        io.cprint(\n            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')\n        torch.cuda.manual_seed(args.seed)\n    else:\n        io.cprint('Using CPU')\n\n    if not args.eval:\n        train(args, io)\n    else:\n        test(args, io)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-03-29T02:35:37.233321Z","iopub.execute_input":"2023-03-29T02:35:37.233908Z","iopub.status.idle":"2023-03-29T02:35:48.395195Z","shell.execute_reply.started":"2023-03-29T02:35:37.233861Z","shell.execute_reply":"2023-03-29T02:35:48.393679Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Namespace(batch_size=32, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=250, eval=True, exp_name='DGCNN_GC', k=20, lr=0.001, model='dgcnn', model_path='/kaggle/input/model-result/model.t7', momentum=0.9, no_cuda=False, num_points=1024, scheduler='cos', seed=1, test_batch_size=16, use_sgd=True)\nUsing GPU : 0 from 1 devices\n/kaggle /kaggle/input/modelnet40-ply\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3089771478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/3089771478.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(args, io)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/2672410102.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_graph_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 6, 1, 1], expected input[1, 2048, 3, 2] to have 6 channels, but got 2048 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [64, 6, 1, 1], expected input[1, 2048, 3, 2] to have 6 channels, but got 2048 channels instead","output_type":"error"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-03-29T02:08:28.621807Z","iopub.execute_input":"2023-03-29T02:08:28.622304Z","iopub.status.idle":"2023-03-29T02:08:29.709504Z","shell.execute_reply.started":"2023-03-29T02:08:28.622258Z","shell.execute_reply":"2023-03-29T02:08:29.708285Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Wed Mar 29 02:08:29 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0    36W / 250W |   3559MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]}]}